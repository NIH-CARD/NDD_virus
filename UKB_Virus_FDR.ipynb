{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "655ff6bd",
   "metadata": {},
   "source": [
    "# UKB Virus Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8318d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "#Directory in Biowulf\n",
    "os.chdir('/PATH/TO/UKB_Files')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddae7a3",
   "metadata": {},
   "source": [
    "# Loading Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf72c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading all the reference files for UKB\n",
    "NDD_free = pd.read_csv('ALL_NDD_FREE_CONTROLS_AGE60PLUS.txt', delimiter='\\t') #NDD free controls, subset of phenome, all European ancestry\n",
    "phenome = pd.read_csv('covariates_phenome_to_use.txt', delimiter='\\t') #All individuals\n",
    "massive_ICD10 = pd.read_csv('massive_ICD10_ALL_table.txt', delimiter='\\t', header = None) #ICD10 codes per individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdd8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading all the disease files for UKB\n",
    "AD = pd.read_csv(\"alzheimer_disease.txt\", delimiter = '\\t')\n",
    "ALS = pd.read_csv('ALS.IDs', header = None) \n",
    "dementia = pd.read_csv('Dementia.IDs', header = None)\n",
    "PD = pd.read_csv('parkinson_disease.txt', delimiter='\\t')\n",
    "vascular = pd.read_csv('Vascular.IDs', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef48c1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting MS IDs\n",
    "#G35 is the ICD10 code for Multiple sclerosis\n",
    "G35 = massive_ICD10.loc[massive_ICD10[1] == 'G35']\n",
    "list_MS = G35[0]\n",
    "MS = phenome[phenome['IID'].isin(list_MS)]\n",
    "MS = MS.rename(columns = {'FID': 0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df841c2c",
   "metadata": {},
   "source": [
    "# Adding Disease Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c2d22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick your NDD here\n",
    "NDD = AD\n",
    "ndd = \"AD\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc86bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add disease column to NDD free df\n",
    "NDD_free[ndd] = 0\n",
    "\n",
    "#Drop FID, Batch, and European\n",
    "NDD_free = NDD_free.drop(columns = ['FID', 'BATCH', \"EUROPEAN\"])\n",
    "\n",
    "#Rename ID column\n",
    "NDD_free = NDD_free.rename(columns = {'IID': 'ID'})\n",
    "print(\"Number of controls:\", len(NDD_free))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b55b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating df of people with NDD\n",
    "NDD = NDD.rename(columns = {'eid': 0})\n",
    "NDD_list = list(NDD[0])\n",
    "has_NDD = phenome[phenome['IID'].isin(NDD_list)]\n",
    "\n",
    "#Only select Europeans to match controls\n",
    "has_NDD = has_NDD[has_NDD['EUROPEAN'] == 1]\n",
    "\n",
    "#Drop FID, Batch, and European\n",
    "has_NDD = has_NDD.drop(columns = ['FID', 'BATCH', \"EUROPEAN\"])\n",
    "\n",
    "#Rename ID column\n",
    "has_NDD = has_NDD.rename(columns = {'IID': 'ID'})\n",
    "\n",
    "#Add NDD column\n",
    "has_NDD[ndd] = 1\n",
    "\n",
    "print(f\"Number of individuals with {ndd}:\", len(has_NDD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a5c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine NDD_free and has_NDD\n",
    "df = pd.concat([NDD_free, has_NDD])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539792e2",
   "metadata": {},
   "source": [
    "# Adding ICD10 Codes to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc6dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of codes -- see Supplementary Table 1\n",
    "search_terms = pd.read_csv('Supplementary_Table_1 - FinnGen_Codes.csv')\n",
    "\n",
    "phenocode_list = list(search_terms['FinnGen Phenocode'].drop_duplicates())\n",
    "ukb_codes = search_terms.loc[search_terms['Cohort']=='UKB']\n",
    "ukb_code_list = list(ukb_codes['ICD10 Codes'])\n",
    "predictor_meaning = list(search_terms['Description'].drop_duplicates())\n",
    "\n",
    "unique_codes = []\n",
    "for code in ukb_code_list:\n",
    "    unique_codes.append(code.split(','))\n",
    "\n",
    "clean = []\n",
    "for i in unique_codes[0]:\n",
    "    clean.append(i.strip())\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e412e883",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique codes:\", len(unique_codes))\n",
    "print(\"Phenocode_list:\", len(phenocode_list))\n",
    "phenocode_list\n",
    "\n",
    "flat_list = []\n",
    "for xs in unique_codes:\n",
    "    for x in xs:\n",
    "        flat_list.append(x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82a068d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding Viral codes in ICD10 list\n",
    "for code in flat_list:\n",
    "    viral_ICD10 = massive_ICD10[massive_ICD10[1] == code]\n",
    "    viral_ICD10 = viral_ICD10.rename(columns = {0: 'ID', 1: \"Code\"})\n",
    "    viral_ICD10 = list(viral_ICD10[\"ID\"])\n",
    "    df[code] = np.where(df['ID'].isin(viral_ICD10), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a5449d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking that ICD10 columns were added\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f012f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Unique codes:\", len(unique_codes))\n",
    "#print(unique_codes)\n",
    "print(\"Phenocode_list:\", len(phenocode_list))\n",
    "#print(phenocode_list)\n",
    "print(unique_codes[0])\n",
    "print(phenocode_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a806e115",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding the FinnGen Groupings to the dataframe\n",
    "for j in range(len(unique_codes)):\n",
    "    cols = []\n",
    "    for i in unique_codes[j]:\n",
    "        cols.append(i.strip())\n",
    "\n",
    "    df[phenocode_list[j]] = df[cols].sum(axis=1)\n",
    "    df[phenocode_list[j]].values[df[phenocode_list[j]] > 1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97329e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill nan values with 0\n",
    "df = df.fillna(0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7394228a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists for the regression\n",
    "predictor_list = phenocode_list\n",
    "predictor_meaning = predictor_meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675adb3d",
   "metadata": {},
   "source": [
    "# Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679a58ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now nothing left to do is run the regressions and call it a day. \n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "results = []\n",
    "\n",
    "# for predictor in range(1, 10):\n",
    "for predictor in range(len(predictor_list)):\n",
    "  predictor_name = predictor_list[predictor]\n",
    "  predictor_description = predictor_meaning[predictor]\n",
    "  this_formula = ndd + \"~ df['\" + predictor_list[predictor] + \"']\" + \" + AGE_OF_RECRUIT + TOWNSEND + GENETIC_SEX\"\n",
    "  fitted = sm.formula.glm(formula=this_formula, family=sm.families.Binomial(), data=df).fit()\n",
    "  beta_coef  = fitted.params.loc[\"df['\" + predictor_name + \"']\"]\n",
    "  beta_se  = fitted.bse.loc[\"df['\" + predictor_name + \"']\"]\n",
    "  p_val = fitted.pvalues.loc[\"df['\" + predictor_name + \"']\"]\n",
    "  odds_ratio = np.exp(fitted.params.loc[\"df['\" + predictor_name + \"']\"])\n",
    "  conf = fitted.conf_int().loc[\"df['\" + predictor_name + \"']\"]\n",
    "  m5, m95 = np.exp(conf)\n",
    "  n = sum(df[predictor_name])\n",
    "  df2 = df[df[predictor_name]==1]\n",
    "  n_pairs = sum(df2[ndd])  \n",
    "\n",
    "  print(predictor_name, odds_ratio, m5, m95, p_val, n_pairs, n)\n",
    "  results.append((ndd, predictor_name, predictor_description, odds_ratio, m5, m95, p_val, n_pairs, n))\n",
    "\n",
    "output = pd.DataFrame(results, columns=('NDD','CODE', 'DESCRIPTION','odds_ratio', 'ci_min', \"ci_max\", 'P_VAL', \"N_pairs\", \"N\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29db127",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only looking at codes that have at least 3 pairings\n",
    "output = output[output['N_pairs'] > 2]\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccedf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding FDR Correction\n",
    "\n",
    "#Sort P-values\n",
    "output = output.sort_values(by = \"P_VAL\")\n",
    "\n",
    "#Drop Nan-values\n",
    "output = output.dropna()\n",
    "\n",
    "#FDR Correction\n",
    "rejected, p_corr = fdrcorrection(output['P_VAL'], is_sorted=True)\n",
    "output['P_CORR'] = p_corr\n",
    "output['REJECTED'] = rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d159750",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check results\n",
    "output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a59d748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save output\n",
    "output.to_csv('/PATH/TO/regression_results/' + ndd + \"_virus_UKB_ALL.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
